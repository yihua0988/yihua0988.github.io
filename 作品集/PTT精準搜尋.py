# -*- coding: utf-8 -*-
"""
PTT ç²¾æº–æœå°‹ï¼ˆä¸‰ç€è¦½å™¨é€šç”¨ + è‡ªå‹• driver ä¸‹è¼‰ï¼‰
åŠŸèƒ½ï¼š
 - æ”¯æ´ Chrome / Edge / Firefoxï¼ˆwebdriver_manager è‡ªå‹•å®‰è£ driverï¼‰
 - å–å¾—ï¼šçœ‹æ¿ã€ä¸»è¦é—œéµå­—ã€é€²éšç¯©é¸ã€å¹´ä»½ã€å®Œæ•´æ™‚é–“/åˆ—è¡¨æ—¥æœŸã€æ¨™é¡Œã€ä½œè€…ã€é€£çµ
 - å„²å­˜åˆ°ç•¶å‰è³‡æ–™å¤¾ PTTæœå°‹ç´€éŒ„.xlsxï¼ˆè‹¥å·²å­˜åœ¨å‰‡è¿½åŠ ï¼‰
"""
import os
import sys
import time
import pandas as pd
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.edge.service import Service as EdgeService
from selenium.webdriver.firefox.service import Service as FirefoxService
from selenium.webdriver.chrome.options import Options as ChromeOptions
from selenium.webdriver.edge.options import Options as EdgeOptions
from selenium.webdriver.firefox.options import Options as FirefoxOptions
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.microsoft import EdgeChromiumDriverManager
from webdriver_manager.firefox import GeckoDriverManager

sys.stderr = open(os.devnull, 'w')
def get_driver():
    # Chrome
    try:
        chrome_options = ChromeOptions()
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--log-level=3")  
        chrome_options.add_experimental_option("excludeSwitches", ["enable-logging", "enable-automation"])
        driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=chrome_options)
        print("âœ… ä½¿ç”¨ Chrome ç€è¦½å™¨")
        return driver
    except Exception as e:
        print("âŒ Chrome å•Ÿå‹•å¤±æ•—ï¼š", e)

    # Edge
    try:
        edge_options = EdgeOptions()
        edge_options.add_argument("--headless=new")
        edge_options.add_argument("--disable-gpu")
        edge_options.add_argument("--no-sandbox")
        edge_options.add_argument("--disable-dev-shm-usage")
        edge_options.add_argument("--log-level=3")
        edge_options.add_experimental_option("excludeSwitches", ["enable-logging", "enable-automation"])
        driver = webdriver.Edge(service=EdgeService(EdgeChromiumDriverManager().install()), options=edge_options)
        print("âœ… ä½¿ç”¨ Edge ç€è¦½å™¨")
        return driver
    except Exception as e:
        print("âŒ Edge å•Ÿå‹•å¤±æ•—ï¼š", e)

    # Firefox
    try:
        # éš±è— geckodriver å’Œ selenium çš„éŒ¯èª¤è¨Šæ¯
        firefox_options = FirefoxOptions()
        firefox_options.add_argument("--headless")       
        firefox_options.log.level = "fatal"             

        driver = webdriver.Firefox(
            service=FirefoxService(GeckoDriverManager().install()),
            options=firefox_options
        )
        print("âœ… ä½¿ç”¨ Firefox ç€è¦½å™¨")
        return driver

    except Exception as e:
            print("âŒ Firefox å•Ÿå‹•å¤±æ•—ï¼š", e)

    raise RuntimeError("âš ï¸ æ‰¾ä¸åˆ°ä»»ä½•å¯ç”¨çš„ç€è¦½å™¨ Driverã€‚è«‹ç¢ºèªç³»çµ±æœ‰å®‰è£ Chromeã€Edge æˆ– Firefoxã€‚")

def extract_full_time_from_article(driver, article_url):
    """å˜—è©¦å¾æ–‡ç« ä¸­æŠ“å–å®Œæ•´ç™¼æ–‡æ™‚é–“èˆ‡å¹´ä»½"""
    try:
        driver.execute_script("window.open(arguments[0], '_blank');", article_url)
        driver.switch_to.window(driver.window_handles[-1])
        time.sleep(1)

        meta_lines = driver.find_elements(By.CSS_SELECTOR, "div.article-metaline")
        for line in meta_lines:
            try:
                tag = line.find_element(By.CLASS_NAME, "article-meta-tag").text.strip()
                if tag == "æ™‚é–“":
                    raw_time = line.find_element(By.CLASS_NAME, "article-meta-value").text.strip()
                    try:
                        dt = datetime.strptime(raw_time, "%a %b %d %H:%M:%S %Y")
                        driver.close()
                        driver.switch_to.window(driver.window_handles[0])
                        return dt.strftime("%Y-%m-%d %H:%M:%S"), dt.year
                    except ValueError:
                        # ç„¡æ³•è§£ææ™‚é–“æ ¼å¼ï¼Œå›å‚³åŸå­—ä¸²
                        driver.close()
                        driver.switch_to.window(driver.window_handles[0])
                        return raw_time, None
            except:
                continue

        driver.close()
        driver.switch_to.window(driver.window_handles[0])
        return None, None

    except Exception:
        # è‹¥å‡ºéŒ¯ï¼Œç¢ºä¿é—œé–‰åˆ†é 
        try:
            if len(driver.window_handles) > 1:
                driver.close()
                driver.switch_to.window(driver.window_handles[0])
        except:
            pass
        return None, None

def crawl_ptt(board, main_keyword, extra_keywords, max_pages=5):
    driver = get_driver()
    base_url = f"https://www.ptt.cc/bbs/{board}/search?q={main_keyword}"
    driver.get(base_url)
    time.sleep(1)

    # é€šéå¹´é½¡é©—è­‰é é¢
    try:
        if "over18" in driver.current_url:
            try:
                driver.find_element(By.NAME, "yes").click()
            except:
                try:
                    driver.find_element(By.XPATH, '//button[text()="æˆ‘åŒæ„ï¼Œæˆ‘å·²å¹´æ»¿åå…«æ­²"]').click()
                except:
                    pass
            time.sleep(1)
    except:
        pass

    records = []
    page = 1
    while page <= max_pages:
        print(f"ğŸ“„ æ­£åœ¨çˆ¬å–ç¬¬ {page} é ...")
        time.sleep(1)

        entries = driver.find_elements(By.CSS_SELECTOR, "div.r-ent")
        if not entries:
            break

        for ent in entries:
            try:
                title_elem = ent.find_element(By.CSS_SELECTOR, "div.title")
                links = title_elem.find_elements(By.TAG_NAME, "a")
                if not links:
                    continue
                title = links[0].text.strip()
                href = links[0].get_attribute("href")
                author = ent.find_element(By.CSS_SELECTOR, "div.meta div.author").text.strip()
                date_text = ent.find_element(By.CSS_SELECTOR, "div.meta div.date").text.strip()  # e.g. 11/06

                # é—œéµå­—éæ¿¾
                if extra_keywords:
                    if not all(k.lower() in title.lower() for k in extra_keywords):
                        continue

                # æŠ“å®Œæ•´æ™‚é–“
                full_time, year = extract_full_time_from_article(driver, href)

                # è‹¥æŠ“ä¸åˆ°å®Œæ•´æ™‚é–“ï¼Œç”¨åˆ—è¡¨æ—¥æœŸè£œå¹´ä»½
                if not full_time:
                    try:
                        m, d = date_text.strip().split("/")
                        m, d = int(m), int(d)
                        now = datetime.now()
                        if (m, d) > (now.month, now.day):
                            guessed_year = now.year - 1
                        else:
                            guessed_year = now.year
                        full_time = f"{guessed_year}-{m:02d}-{d:02d}"
                        year = guessed_year
                    except:
                        full_time = date_text
                        year = datetime.now().year

                records.append({
                    "çœ‹æ¿": board,
                    "ä¸»è¦é—œéµå­—": main_keyword,
                    "é€²éšç¯©é¸": " ".join(extra_keywords),
                    "å¹´ä»½": year,
                    "å®Œæ•´æ™‚é–“æˆ–åˆ—è¡¨æ—¥æœŸ": full_time,
                    "æ¨™é¡Œ": title,
                    "ä½œè€…": author,
                    "é€£çµ": href
                })
            except Exception:
                continue

        # ä¸Šé é€£çµ
        try:
            prev_link = driver.find_element(By.LINK_TEXT, "â€¹ ä¸Šé ")
            href = prev_link.get_attribute("href")
            if not href:
                break
            driver.get(href)
            page += 1
        except:
            break

    driver.quit()
    return records

def save_to_excel(records, filename="PTTæœå°‹ç´€éŒ„.xlsx"):
    if not records:
        print("âš ï¸ æ²’æœ‰è³‡æ–™å¯å„²å­˜ã€‚")
        return

    df = pd.DataFrame(records)
    save_path = os.path.join(os.getcwd(), filename)
    if os.path.exists(save_path):
        try:
            old_df = pd.read_excel(save_path)
            df = pd.concat([old_df, df], ignore_index=True)
        except Exception as e:
            print("è®€å–èˆŠæª”å¤±æ•—ï¼š", e)
    df.to_excel(save_path, index=False)
    print(f"âœ… å·²å„²å­˜è‡³ {save_path}")

def main():
    board = input("è«‹è¼¸å…¥çœ‹æ¿åç¨±ï¼ˆä¾‹å¦‚ NBAï¼‰ï¼š").strip()
    main_keyword = input("è«‹è¼¸å…¥ä¸»è¦æœå°‹é—œéµå­—ï¼š").strip()
    extra_input = input("å¦‚éœ€é€²ä¸€æ­¥ç¯©é¸æ¨™é¡Œï¼Œè«‹è¼¸å…¥å…¶ä»–é—œéµå­—ï¼ˆç©ºæ ¼åˆ†éš”ï¼Œå¯è·³éï¼‰ï¼š").strip()
    extra_keywords = extra_input.split() if extra_input else []

    print(f"\né–‹å§‹æœå°‹ çœ‹æ¿={board}ï¼Œä¸»è¦é—œéµå­—={main_keyword}ï¼Œé€²éšç¯©é¸={' '.join(extra_keywords)}\n")
    records = crawl_ptt(board, main_keyword, extra_keywords)
    print(f"\nå…±æ“·å–åˆ° {len(records)} ç­†è³‡æ–™ã€‚")
    save_to_excel(records)


if __name__ == "__main__":
    main()
